from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from openai import OpenAI
import json
import asyncio
import httpx
import os
from typing import List, Dict

app = FastAPI()

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æŒ‚è½½é™æ€æ–‡ä»¶ç›®å½•
app.mount("/static", StaticFiles(directory="static"), name="static")

# é…ç½®OpenAIå®¢æˆ·ç«¯è¿æ¥åˆ°MiniMax
api_key = os.getenv("MINIMAX_API_KEY")
client = OpenAI(
    base_url="https://api.minimaxi.com/v1",
    api_key=api_key
)

# å®šä¹‰å·¥å…·ï¼šå¤©æ°”æŸ¥è¯¢
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "è·å–æŒ‡å®šåŸå¸‚çš„å®æ—¶å¤©æ°”ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ¸©åº¦ã€å¤©æ°”çŠ¶å†µã€æ¹¿åº¦ç­‰ã€‚ç”¨æˆ·éœ€è¦å…ˆæä¾›ä¸€ä¸ªåŸå¸‚åç§°ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "åŸå¸‚åç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€ä¸Šæµ·ã€San Francisco ç­‰"
                    }
                },
                "required": ["location"]
            }
        }
    }
]


async def get_weather(location: str) -> str:
    """
    è°ƒç”¨wttr.inå…è´¹å¤©æ°”APIè·å–å®æ—¶å¤©æ°”
    å‚æ•°ï¼š
        location: åŸå¸‚åç§°
    è¿”å›ï¼š
        å¤©æ°”ä¿¡æ¯çš„JSONå­—ç¬¦ä¸²
    """
    try:
        async with httpx.AsyncClient() as client_http:
            url = f"https://wttr.in/{location}?format=j1"
            response = await client_http.get(url, timeout=10.0)
            
            if response.status_code == 200:
                data = response.json()
                current = data['current_condition'][0]
                
                weather_info = {
                    "location": location,
                    "temperature": f"{current['temp_C']}Â°C",
                    "feels_like": f"{current['FeelsLikeC']}Â°C",
                    "condition": current['weatherDesc'][0]['value'],
                    "humidity": f"{current['humidity']}%",
                    "wind_speed": f"{current['windspeedKmph']} km/h",
                    "wind_direction": current['winddir16Point'],
                    "pressure": f"{current['pressure']} mb",
                    "visibility": f"{current['visibility']} km",
                    "uv_index": current['uvIndex']
                }
                
                return json.dumps(weather_info, ensure_ascii=False)
            else:
                return json.dumps({"error": f"æ— æ³•è·å–{location}çš„å¤©æ°”ä¿¡æ¯"}, ensure_ascii=False)
                
    except Exception as e:
        return json.dumps({"error": f"å¤©æ°”æŸ¥è¯¢å¤±è´¥: {str(e)}"}, ensure_ascii=False)


@app.get("/")
async def read_root():
    """é‡å®šå‘åˆ°é™æ€é¡µé¢"""
    from fastapi.responses import FileResponse
    return FileResponse("static/index.html")


@app.post("/api/chat/stream")
async def chat_stream(request: Request):
    """æµå¼èŠå¤©æ¥å£ï¼ˆæ”¯æŒå·¥å…·è°ƒç”¨ï¼‰"""
    try:
        # è§£æè¯·æ±‚ä½“
        body = await request.json()
        messages = body.get("messages", [])
        
        if not messages:
            return {"error": "messageså­—æ®µä¸èƒ½ä¸ºç©º"}
        
        # åˆ›å»ºæµå¼ç”Ÿæˆå™¨
        async def generate():
            try:
                # ç¬¬ä¸€è½®ï¼šè°ƒç”¨æ¨¡å‹ï¼ˆä½¿ç”¨æµå¼ä»¥å®æ—¶è¿”å›æ€è€ƒè¿‡ç¨‹ï¼‰
                stream = client.chat.completions.create(
                    model="MiniMax-M2",
                    messages=messages,
                    tools=tools,
                    extra_body={"reasoning_split": True},
                    stream=True,
                )
                
                # æ”¶é›†å®Œæ•´çš„å“åº”æ¶ˆæ¯ï¼ˆç”¨äºæ£€æµ‹tool_callsï¼‰
                full_content = ""
                tool_calls_list = []
                reasoning_content = []
                
                # å¤„ç†ç¬¬ä¸€è½®æµå¼å“åº”
                for chunk in stream:
                    try:
                        delta = chunk.choices[0].delta
                    except Exception:
                        continue
                    
                    # å®æ—¶å‘é€æ€è€ƒè¿‡ç¨‹
                    rd = getattr(delta, "reasoning_details", None)
                    if rd:
                        for detail in rd:
                            if isinstance(detail, dict) and "text" in detail and detail["text"]:
                                reasoning_content.append(detail["text"])
                                data = json.dumps({"type": "thinking", "content": detail["text"]}, ensure_ascii=False)
                                yield f"data: {data}\n\n"
                                await asyncio.sleep(0.01)
                    
                    # æ”¶é›†å†…å®¹ï¼ˆæš‚ä¸å‘é€ï¼Œç­‰ç¡®è®¤æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨ï¼‰
                    content_fragment = getattr(delta, "content", None)
                    if content_fragment:
                        full_content += content_fragment
                    
                    # æ”¶é›†å·¥å…·è°ƒç”¨ä¿¡æ¯
                    tool_calls = getattr(delta, "tool_calls", None)
                    if tool_calls:
                        for tc in tool_calls:
                            # æŸ¥æ‰¾æˆ–åˆ›å»ºå¯¹åº”çš„tool_call
                            idx = tc.index if hasattr(tc, "index") else 0
                            while len(tool_calls_list) <= idx:
                                tool_calls_list.append({"id": "", "type": "function", "function": {"name": "", "arguments": ""}})
                            
                            if hasattr(tc, "id") and tc.id:
                                tool_calls_list[idx]["id"] = tc.id
                            if hasattr(tc, "function"):
                                if hasattr(tc.function, "name") and tc.function.name:
                                    tool_calls_list[idx]["function"]["name"] = tc.function.name
                                if hasattr(tc.function, "arguments") and tc.function.arguments:
                                    tool_calls_list[idx]["function"]["arguments"] += tc.function.arguments
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                if tool_calls_list:
                    # å‘é€å·¥å…·è°ƒç”¨ä¿¡æ¯
                    for tool_call in tool_calls_list:
                        tool_info = f"ğŸ”§ æ­£åœ¨è°ƒç”¨å·¥å…·: {tool_call['function']['name']}\n"
                        data = json.dumps({"type": "content", "content": tool_info}, ensure_ascii=False)
                        yield f"data: {data}\n\n"
                        await asyncio.sleep(0.01)
                    
                    # å°†å®Œæ•´çš„assistantå“åº”æ·»åŠ åˆ°æ¶ˆæ¯å†å²
                    messages.append({
                        "role": "assistant",
                        "content": full_content or None,
                        "tool_calls": tool_calls_list
                    })
                    
                    # æ‰§è¡Œå·¥å…·è°ƒç”¨
                    for tool_call in tool_calls_list:
                        function_name = tool_call['function']['name']
                        function_args = json.loads(tool_call['function']['arguments'])
                        
                        if function_name == "get_weather":
                            location = function_args.get("location")
                            tool_result = await get_weather(location)
                            
                            # å‘é€å·¥å…·æ‰§è¡Œç»“æœä¿¡æ¯
                            result_info = f"ğŸ“Š è·å–åˆ°{location}çš„å¤©æ°”ä¿¡æ¯\n"
                            data = json.dumps({"type": "content", "content": result_info}, ensure_ascii=False)
                            yield f"data: {data}\n\n"
                            await asyncio.sleep(0.01)
                            
                            # æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯å†å²
                            messages.append({
                                "role": "tool",
                                "tool_call_id": tool_call['id'],
                                "content": tool_result
                            })
                    
                    # ç¬¬äºŒè½®ï¼šä½¿ç”¨æµå¼è·å–æœ€ç»ˆå›å¤
                    stream = client.chat.completions.create(
                        model="MiniMax-M2",
                        messages=messages,
                        tools=tools,
                        extra_body={"reasoning_split": True},
                        stream=True,
                    )
                    
                    # å¤„ç†æµå¼å“åº”
                    for chunk in stream:
                        try:
                            delta = chunk.choices[0].delta
                        except Exception:
                            continue
                        
                        # å¤„ç†æ€è€ƒè¿‡ç¨‹
                        rd = getattr(delta, "reasoning_details", None)
                        if rd:
                            for detail in rd:
                                if isinstance(detail, dict) and "text" in detail and detail["text"]:
                                    data = json.dumps({"type": "thinking", "content": detail["text"]}, ensure_ascii=False)
                                    yield f"data: {data}\n\n"
                                    await asyncio.sleep(0.01)
                        
                        # å¤„ç†å“åº”å†…å®¹
                        content_fragment = getattr(delta, "content", None)
                        if content_fragment:
                            data = json.dumps({"type": "content", "content": content_fragment}, ensure_ascii=False)
                            yield f"data: {data}\n\n"
                            await asyncio.sleep(0.01)
                
                else:
                    # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œæµå¼å‘é€å·²æ”¶é›†çš„å†…å®¹
                    if full_content:
                        # ç›´æ¥å®æ—¶å‘é€ï¼ˆåœ¨æµå¼å¤„ç†ä¸­å…¶å®å·²ç»å¯ä»¥å‘é€äº†ï¼Œè¿™é‡Œåˆ†å—å‘é€ï¼‰
                        chunk_size = 10
                        for i in range(0, len(full_content), chunk_size):
                            chunk_text = full_content[i:i+chunk_size]
                            data = json.dumps({"type": "content", "content": chunk_text}, ensure_ascii=False)
                            yield f"data: {data}\n\n"
                            await asyncio.sleep(0.01)
                
                # å‘é€å®Œæˆä¿¡å·
                yield "data: [DONE]\n\n"
                
            except Exception as e:
                error_msg = f"é”™è¯¯: {str(e)}"
                yield f"data: {error_msg}\n\n"
        
        return StreamingResponse(
            generate(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )
        
    except Exception as e:
        return {"error": str(e)}


@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return {"status": "ok", "message": "MiniMax ChatæœåŠ¡è¿è¡Œä¸­"}


if __name__ == "__main__":
    import uvicorn
    print("=" * 60)
    print("MiniMax Chat WebæœåŠ¡å¯åŠ¨ä¸­...")
    print("è®¿é—®åœ°å€: http://localhost:8000")
    print("=" * 60)
    uvicorn.run(app, host="0.0.0.0", port=8000)

